# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'ImageProcessingMidterm.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes mapipde to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

import cv2 as cv
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QFileDialog
import traceback
import numpy as np


class Ui_MainWindow(object):
    image = None

    def setupUi(self, MainWindow):
        self.MainWindow = MainWindow
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(900, 600)
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")

        # Load Image buttons on the left, vertically centered
        self.loadImage1 = QtWidgets.QPushButton("Load Image", self.centralwidget)
        self.loadImage1.setGeometry(QtCore.QRect(20, 230, 180, 30))  # Adjusted Y position to center vertically

        # Group 1: Image Processing in the center, at the top
        self.groupBox1 = QtWidgets.QGroupBox("1. Image Processing", self.centralwidget)
        self.groupBox1.setGeometry(QtCore.QRect(220, 20, 200, 140))
        self.pushButton_1_1 = QtWidgets.QPushButton("1.1 Color Separation", self.groupBox1)
        self.pushButton_1_1.setGeometry(QtCore.QRect(10, 20, 180, 30))
        self.pushButton_1_2 = QtWidgets.QPushButton("1.2 Color Transformation", self.groupBox1)
        self.pushButton_1_2.setGeometry(QtCore.QRect(10, 50, 180, 30))
        self.pushButton_1_3 = QtWidgets.QPushButton("1.3 Color Extraction", self.groupBox1)
        self.pushButton_1_3.setGeometry(QtCore.QRect(10, 80, 180, 30))

        # Group 2: Image Smoothing in the center, below Image Processing
        self.groupBox2 = QtWidgets.QGroupBox("2. Image Smoothing", self.centralwidget)
        self.groupBox2.setGeometry(QtCore.QRect(220, 170, 200, 150))
        self.pushButton_2_1 = QtWidgets.QPushButton("2.1 Gaussian Blur", self.groupBox2)
        self.pushButton_2_1.setGeometry(QtCore.QRect(10, 20, 180, 30))
        self.pushButton_2_2 = QtWidgets.QPushButton("2.2 Bilateral Filter", self.groupBox2)
        self.pushButton_2_2.setGeometry(QtCore.QRect(10, 60, 180, 30))
        self.pushButton_2_3 = QtWidgets.QPushButton("2.3 Median Filter", self.groupBox2)
        self.pushButton_2_3.setGeometry(QtCore.QRect(10, 100, 180, 30))

        # Group 3: Edge Detection in the center, below Image Smoothing
        self.groupBox3 = QtWidgets.QGroupBox("3. Edge Detection", self.centralwidget)
        self.groupBox3.setGeometry(QtCore.QRect(220, 330, 200, 180))
        self.pushButton_3_1 = QtWidgets.QPushButton("3.1 Sobel X", self.groupBox3)
        self.pushButton_3_1.setGeometry(QtCore.QRect(10, 20, 180, 30))
        self.pushButton_3_2 = QtWidgets.QPushButton("3.2 Sobel Y", self.groupBox3)
        self.pushButton_3_2.setGeometry(QtCore.QRect(10, 60, 180, 30))
        self.pushButton_3_3 = QtWidgets.QPushButton("3.3 Combination and Threshold", self.groupBox3)
        self.pushButton_3_3.setGeometry(QtCore.QRect(10, 100, 180, 30))
        self.pushButton_3_4 = QtWidgets.QPushButton("3.4 Gradient Angle", self.groupBox3)
        self.pushButton_3_4.setGeometry(QtCore.QRect(10, 140, 180, 30))

        # Group 4: Transforms on the right
        self.groupBox4 = QtWidgets.QGroupBox("4. Transforms", self.centralwidget)
        self.groupBox4.setGeometry(QtCore.QRect(450, 20, 200, 180))
        self.rotationLabel = QtWidgets.QLabel("Rotation:", self.groupBox4)
        self.rotationLabel.setGeometry(QtCore.QRect(10, 20, 60, 20))
        self.rotationInput = QtWidgets.QLineEdit(self.groupBox4)
        self.rotationInput.setGeometry(QtCore.QRect(80, 20, 70, 20))
        self.rotationUnit = QtWidgets.QLabel("deg", self.groupBox4)
        self.rotationUnit.setGeometry(QtCore.QRect(160, 20, 30, 20))

        self.scalingLabel = QtWidgets.QLabel("Scaling:", self.groupBox4)
        self.scalingLabel.setGeometry(QtCore.QRect(10, 50, 60, 20))
        self.scalingInput = QtWidgets.QLineEdit(self.groupBox4)
        self.scalingInput.setGeometry(QtCore.QRect(80, 50, 70, 20))

        self.txLabel = QtWidgets.QLabel("Tx:", self.groupBox4)
        self.txLabel.setGeometry(QtCore.QRect(10, 80, 60, 20))
        self.txInput = QtWidgets.QLineEdit(self.groupBox4)
        self.txInput.setGeometry(QtCore.QRect(80, 80, 70, 20))
        self.txUnit = QtWidgets.QLabel("pixel", self.groupBox4)
        self.txUnit.setGeometry(QtCore.QRect(160, 80, 30, 20))

        self.tyLabel = QtWidgets.QLabel("Ty:", self.groupBox4)
        self.tyLabel.setGeometry(QtCore.QRect(10, 110, 60, 20))
        self.tyInput = QtWidgets.QLineEdit(self.groupBox4)
        self.tyInput.setGeometry(QtCore.QRect(80, 110, 70, 20))
        self.tyUnit = QtWidgets.QLabel("pixel", self.groupBox4)
        self.tyUnit.setGeometry(QtCore.QRect(160, 110, 30, 20))

        self.pushButton_4 = QtWidgets.QPushButton("4. Transforms", self.groupBox4)
        self.pushButton_4.setGeometry(QtCore.QRect(10, 140, 180, 30))

        # Set central widget
        MainWindow.setCentralWidget(self.centralwidget)
        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

        self.loadImage1.clicked.connect(self.LoadImage)
        self.pushButton_1_1.clicked.connect(self.ColorSeparation)
        self.pushButton_1_2.clicked.connect(self.ColorTransformation)
        self.pushButton_1_3.clicked.connect(self.ColorExtraction)
        self.pushButton_2_1.clicked.connect(self.GaussianFilter)
        self.pushButton_2_2.clicked.connect(self.BilateralFilter)
        self.pushButton_2_3.clicked.connect(self.MedianFilter)
        self.pushButton_3_1.clicked.connect(self.SobelX)
        self.pushButton_3_2.clicked.connect(self.SobelY)
        self.pushButton_3_3.clicked.connect(self.CombinationAndThreshold)
        self.pushButton_3_4.clicked.connect(self.GradientAngle)
        self.pushButton_4.clicked.connect(self.applyTransformations)

    def retranslateUi(self, MainWindow):
        MainWindow.setWindowTitle(QtCore.QCoreApplication.translate("MainWindow", "Image Processing"))

        self.loadImage1.setText(QtCore.QCoreApplication.translate("MainWindow", "Load Image"))

        # Group 1: Image Processing
        self.groupBox1.setTitle(QtCore.QCoreApplication.translate("MainWindow", "1. Image Processing"))
        self.pushButton_1_1.setText(QtCore.QCoreApplication.translate("MainWindow", "1.1 Color Separation"))
        self.pushButton_1_2.setText(QtCore.QCoreApplication.translate("MainWindow", "1.2 Color Transformation"))
        self.pushButton_1_3.setText(QtCore.QCoreApplication.translate("MainWindow", "1.3 Color Extraction"))

        # Group 2: Image Smoothing
        self.groupBox2.setTitle(QtCore.QCoreApplication.translate("MainWindow", "2. Image Smoothing"))
        self.pushButton_2_1.setText(QtCore.QCoreApplication.translate("MainWindow", "2.1 Gaussian Blur"))
        self.pushButton_2_2.setText(QtCore.QCoreApplication.translate("MainWindow", "2.2 Bilateral Filter"))
        self.pushButton_2_3.setText(QtCore.QCoreApplication.translate("MainWindow", "2.3 Median Filter"))

        # Group 3: Edge Detection
        self.groupBox3.setTitle(QtCore.QCoreApplication.translate("MainWindow", "3. Edge Detection"))
        self.pushButton_3_1.setText(QtCore.QCoreApplication.translate("MainWindow", "3.1 Sobel X"))
        self.pushButton_3_2.setText(QtCore.QCoreApplication.translate("MainWindow", "3.2 Sobel Y"))
        self.pushButton_3_3.setText(QtCore.QCoreApplication.translate("MainWindow", "3.3 Combination and Threshold"))
        self.pushButton_3_4.setText(QtCore.QCoreApplication.translate("MainWindow", "3.4 Gradient Angle"))

        # Group 4: Transforms
        self.groupBox4.setTitle(QtCore.QCoreApplication.translate("MainWindow", "4. Transforms"))
        self.rotationLabel.setText(QtCore.QCoreApplication.translate("MainWindow", "Rotation:"))
        self.scalingLabel.setText(QtCore.QCoreApplication.translate("MainWindow", "Scaling:"))
        self.txLabel.setText(QtCore.QCoreApplication.translate("MainWindow", "Tx:"))
        self.tyLabel.setText(QtCore.QCoreApplication.translate("MainWindow", "Ty:"))
        self.pushButton_4.setText(QtCore.QCoreApplication.translate("MainWindow", "4. Transforms"))

    def LoadImage(self):
        try:
            # Open a file dialog to select an image
            file_dialog = QFileDialog()
            file_path, _ = file_dialog.getOpenFileName(None, "Open Image File", "",
                                                       "Image Files (*.png *.jpg *.bmp *jfif)")

            if file_path:
                # Load the image using OpenCV
                self.image = cv.imread(file_path)

                # Convert the OpenCV image (BGR) to RGB for displaying
                image_rgb = cv.cvtColor(self.image, cv.COLOR_BGR2RGB)

                # Create a QImage from the RGB image
                height, width, channel = image_rgb.shape
                bytes_per_line = 3 * width
                q_image = QtGui.QImage(image_rgb.data, width, height, bytes_per_line, QtGui.QImage.Format_RGB888)

                # Create a QLabel to display the QImage
                image_label = QtWidgets.QLabel()
                image_label.setPixmap(QtGui.QPixmap.fromImage(q_image))
                image_label.setAlignment(QtCore.Qt.AlignCenter)

                # Create a new window to display the image
                self.image_window = QtWidgets.QMainWindow()
                self.image_window.setWindowTitle("Loaded Image")
                self.image_window.setCentralWidget(image_label)
                self.image_window.resize(width, height)
                self.image_window.show()

                # Placeholder for the second Load Image button functionality
                # if self.loadImage2.isClicked():
                #     self.image_window2 = QtWidgets.QMainWindow()
                #     self.image_window2.setWindowTitle("Loaded Image 2")
                #     self.image_window2.setCentralWidget(image_label) # Modify appropriately for a second image
                #     self.image_window2.resize(width, height)
                #     self.image_window2.show()

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")

    def ColorSeparation(self):
        try:
            # Ensure an image is loaded
            if self.image is None:
                QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
                return

            # Split the BGR channels
            b, g, r = cv.split(self.image)

            # Create a blank (black) image to use in merging
            zeros = np.zeros_like(b)

            # Create images for each channel with others set to zero
            b_image = cv.merge([b, zeros, zeros])  # Only Blue channel
            g_image = cv.merge([zeros, g, zeros])  # Only Green channel
            r_image = cv.merge([zeros, zeros, r])  # Only Red channel

            # Display each channel in a separate window
            self.displayImageInWindow(b_image, "Blue Channel")
            self.displayImageInWindow(g_image, "Green Channel")
            self.displayImageInWindow(r_image, "Red Channel")

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")

    def ColorTransformation(self):
        try:
            # Ensure an image is loaded
            if self.image is None:
                QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
                return

            # Q1: Convert image to grayscale using OpenCV
            cv_gray = cv.cvtColor(self.image, cv.COLOR_BGR2GRAY)
            self.displayImageInWindow(cv_gray, "Grayscale Image (cv2.cvtColor)")

            # Q2: Generate grayscale by averaging BGR channels
            b, g, r = cv.split(self.image)
            avg_gray = (b / 3 + g / 3 + r / 3).astype(np.uint8)
            self.displayImageInWindow(avg_gray, "Average Grayscale (B+G+R)/3")

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")

    def ColorExtraction(self):
        try:
            # Ensure an image is loaded
            if self.image is None:
                QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
                return

            # Step 1: Convert the image to HSV format
            hsv_image = cv.cvtColor(self.image, cv.COLOR_BGR2HSV)

            # Step 2: Define the yellow-green HSV range and create a mask
            lower_bound = np.array([18, 0, 25])  # HSV lower bound for yellow-green
            upper_bound = np.array([85, 255, 255])  # HSV upper bound for yellow-green
            mask = cv.inRange(hsv_image, lower_bound, upper_bound)
            self.displayImageInWindow(mask, "Yellow-Green Mask (I1)")

            # Step 3: Invert the mask
            mask_inverse = cv.bitwise_not(mask)

            # Step 4: Apply the inverted mask to the original image
            extracted_image = cv.bitwise_and(self.image, self.image, mask=mask_inverse)
            self.displayImageInWindow(extracted_image, "Image without Yellow and Green (I2)")

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")

    def displayImageInWindow(self, image, title):
        # Convert the image to RGB format for display if it has 3 channels
        if len(image.shape) == 3:  # Color image
            image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)
        else:  # Grayscale image
            image_rgb = cv.cvtColor(image, cv.COLOR_GRAY2RGB)

        # Convert the OpenCV image to QImage
        height, width, channel = image_rgb.shape
        bytes_per_line = 3 * width
        q_image = QtGui.QImage(image_rgb.data, width, height, bytes_per_line, QtGui.QImage.Format_RGB888)

        # Create a QLabel to display the QImage
        image_label = QtWidgets.QLabel()
        image_label.setPixmap(QtGui.QPixmap.fromImage(q_image))
        image_label.setAlignment(QtCore.Qt.AlignCenter)

        # Create a new window to display the image
        image_window = QtWidgets.QMainWindow()
        image_window.setWindowTitle(title)
        image_window.setCentralWidget(image_label)
        image_window.resize(width, height)
        image_window.show()

        # Store the window reference to keep it open
        if not hasattr(self, 'image_windows'):
            self.image_windows = []
        self.image_windows.append(image_window)

    def GaussianFilter(self):
        # Ensure an image is loaded
        if self.image is None:
            QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
            return

        # Create a new window
        self.gaussian_window = QtWidgets.QWidget()
        self.gaussian_window.setWindowTitle("Gaussian Filter")

        # Create a vertical layout
        layout = QtWidgets.QVBoxLayout()

        # Create a QSlider for the kernel radius m
        self.slider = QtWidgets.QSlider(QtCore.Qt.Horizontal)
        self.slider.setMinimum(1)
        self.slider.setMaximum(5)
        self.slider.setValue(1)
        self.slider.setTickPosition(QtWidgets.QSlider.TicksBelow)
        self.slider.setTickInterval(1)
        layout.addWidget(self.slider)

        # Create a QLabel to display the image
        self.image_label = QtWidgets.QLabel()
        self.image_label.setAlignment(QtCore.Qt.AlignCenter)
        layout.addWidget(self.image_label)

        # Connect the slider to the update function
        self.slider.valueChanged.connect(self.applyGaussianBlur)

        # Set the layout and show the window
        self.gaussian_window.setLayout(layout)
        self.gaussian_window.show()

        # Apply the initial Gaussian blur
        self.applyGaussianBlur(1)

    def applyGaussianBlur(self, m):
        # Ensure m is at least 1
        m = max(1, m)

        # Calculate the kernel size based on m
        kernel_size = (2 * m + 1, 2 * m + 1)

        # Apply Gaussian blur with the given kernel size
        blurred_image = cv.GaussianBlur(self.image, kernel_size, sigmaX=0, sigmaY=0)

        # Convert the image to RGB format for display if it has 3 channels
        if len(blurred_image.shape) == 3:  # Color image
            image_rgb = cv.cvtColor(blurred_image, cv.COLOR_BGR2RGB)
        else:  # Grayscale image
            image_rgb = cv.cvtColor(blurred_image, cv.COLOR_GRAY2RGB)

        # Convert the OpenCV image to QImage
        height, width, channel = image_rgb.shape
        bytes_per_line = 3 * width
        q_image = QtGui.QImage(image_rgb.data, width, height, bytes_per_line, QtGui.QImage.Format_RGB888)

        # Set the image in the QLabel
        self.image_label.setPixmap(QtGui.QPixmap.fromImage(q_image))
        self.gaussian_window.resize(width, height + 50)  # Adjust window size

    def BilateralFilter(self):
        # Ensure an image is loaded
        if self.image is None:
            QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
            return

        # Create a new window
        self.bilateral_window = QtWidgets.QWidget()
        self.bilateral_window.setWindowTitle("Bilateral Filter")

        # Create a vertical layout
        layout = QtWidgets.QVBoxLayout()
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)

        # Create a label for the slider
        slider_label = QtWidgets.QLabel("Adjust Kernel Radius (m):")
        slider_label.setAlignment(QtCore.Qt.AlignCenter)
        layout.addWidget(slider_label)

        # Create a QSlider for the kernel radius m
        self.bilateral_slider = QtWidgets.QSlider(QtCore.Qt.Horizontal)
        self.bilateral_slider.setMinimum(1)
        self.bilateral_slider.setMaximum(5)
        self.bilateral_slider.setValue(1)
        self.bilateral_slider.setTickPosition(QtWidgets.QSlider.TicksBelow)
        self.bilateral_slider.setTickInterval(1)
        layout.addWidget(self.bilateral_slider)

        # Create a QLabel to display the image
        self.bilateral_image_label = QtWidgets.QLabel()
        self.bilateral_image_label.setAlignment(QtCore.Qt.AlignCenter)
        layout.addWidget(self.bilateral_image_label)

        # Connect the slider to the update function
        self.bilateral_slider.valueChanged.connect(self.applyBilateralFilter)

        # Set the layout and show the window
        self.bilateral_window.setLayout(layout)
        self.bilateral_window.show()

        # Apply the initial bilateral filter
        self.applyBilateralFilter(1)

    def applyBilateralFilter(self, m):
        # Ensure m is at least 1
        m = max(1, m)

        # Calculate the diameter as (2m + 1)
        diameter = 2 * m + 1

        # Apply bilateral filter with the given diameter, sigmaColor=90, sigmaSpace=90
        filtered_image = cv.bilateralFilter(self.image, diameter, sigmaColor=90, sigmaSpace=90)

        # Convert the image to RGB format for display if it has 3 channels
        if len(filtered_image.shape) == 3:  # Color image
            image_rgb = cv.cvtColor(filtered_image, cv.COLOR_BGR2RGB)
        else:  # Grayscale image
            image_rgb = cv.cvtColor(filtered_image, cv.COLOR_GRAY2RGB)

        # Convert the OpenCV image to QImage
        height, width, channel = image_rgb.shape
        bytes_per_line = 3 * width
        q_image = QtGui.QImage(image_rgb.data, width, height, bytes_per_line, QtGui.QImage.Format_RGB888)

        # Set the image in the QLabel
        self.bilateral_image_label.setPixmap(QtGui.QPixmap.fromImage(q_image))
        self.bilateral_window.resize(width + 20, height + 100)  # Adjust window size

    def MedianFilter(self):
        # Ensure an image is loaded
        if self.image is None:
            QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
            return

        # Create a new window
        self.median_window = QtWidgets.QWidget()
        self.median_window.setWindowTitle("Median Filter")

        # Create a vertical layout
        layout = QtWidgets.QVBoxLayout()
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)

        # Create a label for the slider
        slider_label = QtWidgets.QLabel("Adjust Kernel Radius (m):")
        slider_label.setAlignment(QtCore.Qt.AlignCenter)
        layout.addWidget(slider_label)

        # Create a QSlider for the kernel radius m
        self.median_slider = QtWidgets.QSlider(QtCore.Qt.Horizontal)
        self.median_slider.setMinimum(1)
        self.median_slider.setMaximum(5)
        self.median_slider.setValue(1)
        self.median_slider.setTickPosition(QtWidgets.QSlider.TicksBelow)
        self.median_slider.setTickInterval(1)
        layout.addWidget(self.median_slider)

        # Create a QLabel to display the image
        self.median_image_label = QtWidgets.QLabel()
        self.median_image_label.setAlignment(QtCore.Qt.AlignCenter)
        layout.addWidget(self.median_image_label)

        # Connect the slider to the update function
        self.median_slider.valueChanged.connect(self.applyMedianBlur)

        # Set the layout and show the window
        self.median_window.setLayout(layout)
        self.median_window.show()

        # Apply the initial median blur
        self.applyMedianBlur(1)

    def applyMedianBlur(self, m):
        # Ensure m is at least 1
        m = max(1, m)

        # Calculate the kernel size as (2m + 1)
        kernel_size = 2 * m + 1

        # Apply median blur with the given kernel size
        blurred_image = cv.medianBlur(self.image, kernel_size)

        # Convert the image to RGB format for display if it has 3 channels
        if len(blurred_image.shape) == 3:  # Color image
            image_rgb = cv.cvtColor(blurred_image, cv.COLOR_BGR2RGB)
        else:  # Grayscale image
            image_rgb = cv.cvtColor(blurred_image, cv.COLOR_GRAY2RGB)

        # Convert the OpenCV image to QImage
        height, width, channel = image_rgb.shape
        bytes_per_line = 3 * width
        q_image = QtGui.QImage(image_rgb.data, width, height, bytes_per_line, QtGui.QImage.Format_RGB888)

        # Set the image in the QLabel
        self.median_image_label.setPixmap(QtGui.QPixmap.fromImage(q_image))
        self.median_window.resize(width + 20, height + 100)  # Adjust window size

    def SobelX(self):
        try:
            # Ensure an image is loaded
            if self.image is None:
                QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
                return

            # Step 1: Convert to grayscale
            gray_image = cv.cvtColor(self.image, cv.COLOR_BGR2GRAY)

            # Step 2: Apply Gaussian smoothing
            blurred_image = cv.GaussianBlur(gray_image, (3, 3), sigmaX=1, sigmaY=1)

            # Step 3: Apply Sobel X filter manually
            sobel_x_kernel = np.array([[-1, 0, 1],
                                       [-2, 0, 2],
                                       [-1, 0, 1]], dtype=np.float32)

            rows, cols = blurred_image.shape
            sobel_x_image = np.zeros((rows, cols), dtype=np.float32)

            # Perform convolution manually
            for i in range(1, rows - 1):
                for j in range(1, cols - 1):
                    region = blurred_image[i - 1:i + 2, j - 1:j + 2].astype(np.float32)
                    sobel_x_value = np.sum(np.multiply(region, sobel_x_kernel))
                    sobel_x_image[i, j] = sobel_x_value

            # Store the signed gradient image before taking absolute value
            self.sobel_x_signed = sobel_x_image.copy()

            # Normalize the absolute value image for display
            sobel_x_abs = np.abs(sobel_x_image)
            sobel_x_abs = (sobel_x_abs / sobel_x_abs.max()) * 255
            sobel_x_abs = sobel_x_abs.astype(np.uint8)

            # Display the result
            self.displayImageInWindow(sobel_x_abs, "Sobel X Edge Detection")

            # Store the displayed image
            self.sobel_x_image = sobel_x_abs

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")

    def SobelY(self):
        try:
            # Ensure an image is loaded
            if self.image is None:
                QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
                return

            # Step 1: Convert to grayscale
            gray_image = cv.cvtColor(self.image, cv.COLOR_BGR2GRAY)

            # Step 2: Apply Gaussian smoothing
            blurred_image = cv.GaussianBlur(gray_image, (3, 3), sigmaX=1, sigmaY=1)

            # Step 3: Apply Sobel Y filter manually
            sobel_y_kernel = np.array([[-1, -2, -1],
                                       [0, 0, 0],
                                       [1, 2, 1]], dtype=np.float32)

            rows, cols = blurred_image.shape
            sobel_y_image = np.zeros((rows, cols), dtype=np.float32)

            # Perform convolution manually
            for i in range(1, rows - 1):
                for j in range(1, cols - 1):
                    region = blurred_image[i - 1:i + 2, j - 1:j + 2].astype(np.float32)
                    sobel_y_value = np.sum(np.multiply(region, sobel_y_kernel))
                    sobel_y_image[i, j] = sobel_y_value

            # Store the signed gradient image before taking absolute value
            self.sobel_y_signed = sobel_y_image.copy()

            # Normalize the absolute value image for display
            sobel_y_abs = np.abs(sobel_y_image)
            sobel_y_abs = (sobel_y_abs / sobel_y_abs.max()) * 255
            sobel_y_abs = sobel_y_abs.astype(np.uint8)

            # Display the result
            self.displayImageInWindow(sobel_y_abs, "Sobel Y Edge Detection")

            # Store the displayed image
            self.sobel_y_image = sobel_y_abs

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")

    def CombinationAndThreshold(self):
        try:
            # Ensure that Sobel X and Sobel Y images are available
            if not hasattr(self, 'sobel_x_signed') or not hasattr(self, 'sobel_y_signed'):
                QtWidgets.QMessageBox.warning(None, "Warning", "Please compute Sobel X and Sobel Y images first.")
                return

            # Step 1: Combine Sobel X and Sobel Y results using signed gradients
            sobel_x = self.sobel_x_signed
            sobel_y = self.sobel_y_signed
            combined = np.sqrt(np.square(sobel_x) + np.square(sobel_y))

            # Step 2: Normalize the combined result to the range 0-255
            normalized_combined = cv.normalize(combined, None, 0, 255, cv.NORM_MINMAX)
            normalized_combined = normalized_combined.astype(np.uint8)  # Convert back to uint8

            # Store the combined image
            self.combined_image = normalized_combined

            # Step 3: Apply thresholding
            # Threshold at 128
            _, threshold_128 = cv.threshold(normalized_combined, 128, 255, cv.THRESH_BINARY)

            # Threshold at 28
            _, threshold_28 = cv.threshold(normalized_combined, 28, 255, cv.THRESH_BINARY)

            # Step 4: Display each image in a separate window
            self.displayImageInWindow(normalized_combined, "Combined Sobel X and Sobel Y")
            self.displayImageInWindow(threshold_128, "Threshold at 128")
            self.displayImageInWindow(threshold_28, "Threshold at 28")

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")

    def GradientAngle(self):
        try:
            # Ensure that Sobel X, Sobel Y, and Combined images are available
            if not hasattr(self, 'sobel_x_signed') or not hasattr(self, 'sobel_y_signed') or not hasattr(self,
                                                                                                         'combined_image'):
                QtWidgets.QMessageBox.warning(None, "Warning",
                                              "Please compute Sobel X, Sobel Y, and Combined images first.")
                return

            # Step 1: Calculate the gradient angle Î¸ using signed gradients
            sobel_x = self.sobel_x_signed
            sobel_y = self.sobel_y_signed

            gradient_angle = np.arctan2(sobel_y, sobel_x) * (180 / np.pi)
            gradient_angle = (gradient_angle + 360) % 360  # Ensure angles are between 0 and 360 degrees

            # Debug: Check the range of gradient angles
            min_angle = np.min(gradient_angle)
            max_angle = np.max(gradient_angle)
            print(f"Gradient Angle Range: {min_angle} to {max_angle} degrees")

            # Step 2: Generate masks based on the angle ranges
            # Mask for angles between 170 and 190 degrees
            mask_170_190 = np.zeros_like(gradient_angle, dtype=np.uint8)
            condition_170_190 = (gradient_angle >= 170) & (gradient_angle <= 190)
            mask_170_190[condition_170_190] = 255

            # Mask for angles between 260 and 280 degrees
            mask_260_280 = np.zeros_like(gradient_angle, dtype=np.uint8)
            condition_260_280 = (gradient_angle >= 260) & (gradient_angle <= 280)
            mask_260_280[condition_260_280] = 255

            # Debug: Check if masks have any non-zero values
            print(f"Mask 170-190 degrees has {np.count_nonzero(mask_170_190)} pixels")
            print(f"Mask 260-280 degrees has {np.count_nonzero(mask_260_280)} pixels")

            # Step 3: Apply bitwise AND to combine the masks with the combined Sobel image
            combined_image_uint8 = self.combined_image.astype(np.uint8)  # Ensure the combined image is uint8

            result_170_190 = cv.bitwise_and(combined_image_uint8, combined_image_uint8, mask=mask_170_190)
            result_260_280 = cv.bitwise_and(combined_image_uint8, combined_image_uint8, mask=mask_260_280)

            # Step 4: Display the results using PyQt
            self.displayImageInWindow(result_170_190, "Gradient Angle Mask (170-190 degrees)")
            self.displayImageInWindow(result_260_280, "Gradient Angle Mask (260-280 degrees)")

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")

    def applyTransformations(self):
        try:
            # Ensure an image is loaded
            if self.image is None:
                QtWidgets.QMessageBox.warning(None, "Warning", "Please load an image first.")
                return

            # Get transformation parameters from input fields
            # Rotation Angle
            rotation_angle_text = self.rotationInput.text()
            if rotation_angle_text == "":
                QtWidgets.QMessageBox.warning(None, "Warning", "Please enter a rotation angle.")
                return
            try:
                rotation_angle = float(rotation_angle_text)
            except ValueError:
                QtWidgets.QMessageBox.warning(None, "Warning", "Invalid rotation angle. Please enter a number.")
                return

            # Scaling Factor
            scaling_factor_text = self.scalingInput.text()
            if scaling_factor_text == "":
                QtWidgets.QMessageBox.warning(None, "Warning", "Please enter a scaling factor.")
                return
            try:
                scale_factor = float(scaling_factor_text)
                if scale_factor == 0:
                    QtWidgets.QMessageBox.warning(None, "Warning", "Scaling factor cannot be zero.")
                    return
            except ValueError:
                QtWidgets.QMessageBox.warning(None, "Warning", "Invalid scaling factor. Please enter a number.")
                return

            # Translation X (Offset from original center)
            tx_text = self.txInput.text()
            if tx_text == "":
                QtWidgets.QMessageBox.warning(None, "Warning", "Please enter a translation value for Tx.")
                return
            try:
                tx = float(tx_text)
            except ValueError:
                QtWidgets.QMessageBox.warning(None, "Warning", "Invalid Tx value. Please enter a number.")
                return

            # Translation Y (Offset from original center)
            ty_text = self.tyInput.text()
            if ty_text == "":
                QtWidgets.QMessageBox.warning(None, "Warning", "Please enter a translation value for Ty.")
                return
            try:
                ty = float(ty_text)
            except ValueError:
                QtWidgets.QMessageBox.warning(None, "Warning", "Invalid Ty value. Please enter a number.")
                return

            # Get the dimensions of the burger image
            burger_height, burger_width = self.image.shape[:2]
            burger_center = (240, 200)  # Original center of the burger in the image

            # Adjusted desired center position based on offsets
            desired_center_x = burger_center[0] + tx
            desired_center_y = burger_center[1] + ty

            # Create the transformation matrices
            # 1. Move the burger center to the origin
            T_negate_center = np.array([
                [1, 0, -burger_center[0]],
                [0, 1, -burger_center[1]],
                [0, 0, 1]
            ], dtype=np.float32)

            # 2. Scaling and rotation around the origin
            # Reverse the angle to make positive angles rotate counter-clockwise
            theta = np.deg2rad(-rotation_angle)
            cos_theta = np.cos(theta) * scale_factor
            sin_theta = np.sin(theta) * scale_factor

            T_rotation_scaling = np.array([
                [cos_theta, -sin_theta, 0],
                [sin_theta, cos_theta, 0],
                [0, 0, 1]
            ], dtype=np.float32)

            # 3. Move the burger center to the desired position on the canvas
            T_translate = np.array([
                [1, 0, desired_center_x],
                [0, 1, desired_center_y],
                [0, 0, 1]
            ], dtype=np.float32)

            # Combine the transformations: T = T_translate * T_rotation_scaling * T_negate_center
            T = T_translate @ T_rotation_scaling @ T_negate_center

            # Extract the 2x3 affine transformation matrix for cv2.warpAffine
            M = T[:2, :]

            # Canvas size
            canvas_width = 1920
            canvas_height = 1080

            # Apply the affine transformation to the burger image
            transformed_image = cv.warpAffine(self.image, M, (canvas_width, canvas_height), flags=cv.INTER_LINEAR,
                                              borderMode=cv.BORDER_CONSTANT)

            # Display the transformed image
            self.displayImageInWindow(transformed_image, "Transformed Image")

        except Exception as e:
            traceback.print_exc()
            QtWidgets.QMessageBox.critical(None, "Error", f"An error occurred: {str(e)}")


if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())